{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYHvkR9zQNQn"
      },
      "source": [
        "#### Updated Algorithm\n",
        "\n",
        "#### Resume Screening Algorithm Using logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preprocess the Text"
      ],
      "metadata": {
        "id": "9L2_BZwKiHb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('Resume.csv')\n",
        "\n",
        "# Preprocess text function\n",
        "def preprocess_text(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply preprocessing to the resume column\n",
        "data['Resume'] = data['Resume'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "Wdgz_OJk9XBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe2c5c8-5997-42e7-c729-dd95b3431c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. TF-IDF Vectorization\n"
      ],
      "metadata": {
        "id": "u2CE82vMiOaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use TF-IDF to convert text data to numerical features\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X = tfidf.fit_transform(data['Resume'])\n"
      ],
      "metadata": {
        "id": "6lprSPK89W_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Calculate Similarity Scores"
      ],
      "metadata": {
        "id": "n-00IE3wiT1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Function to calculate match percentage\n",
        "def calculate_similarity(job_description, resume_text):\n",
        "    job_features = tfidf.transform([job_description])\n",
        "    resume_features = tfidf.transform([resume_text])\n",
        "    similarity = cosine_similarity(job_features, resume_features)\n",
        "    return similarity[0][0] * 100\n"
      ],
      "metadata": {
        "id": "f9AOsXBva3f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create Labeled Data for Training"
      ],
      "metadata": {
        "id": "ut21GHPJibQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Limit to the first 300 resumes for processing\n",
        "data_subset = data.head(100)"
      ],
      "metadata": {
        "id": "yY4kchQXf2Re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labeled dataset for training suitability model\n",
        "rows = []\n",
        "\n",
        "# Set a threshold for labeling\n",
        "threshold = 30\n",
        "\n",
        "# Generate labels based on similarity scores\n",
        "for i in range(len(data_subset)):\n",
        "    resume_text = data_subset['Resume'].iloc[i]\n",
        "    for j in range(len(data_subset)):\n",
        "        job_description = data_subset['Resume'].iloc[j]\n",
        "        match_percentage = calculate_similarity(job_description, resume_text)\n",
        "        suitable = 1 if match_percentage >= threshold else 0\n",
        "        rows.append({'match_percentage': match_percentage, 'suitable': suitable})"
      ],
      "metadata": {
        "id": "-b9ZdvgYYYkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Train the Logistic Regression Model"
      ],
      "metadata": {
        "id": "LFNmmMAvi452"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert list of rows to DataFrame\n",
        "labeled_data = pd.DataFrame(rows)\n",
        "\n",
        "# Check if labeled_data is created successfully\n",
        "if labeled_data.empty:\n",
        "    print(\"Labeled data is empty. Please check the similarity calculation.\")\n",
        "else:\n",
        "    print(\"Labeled data created successfully.\")\n",
        "    print(labeled_data.head(30))\n",
        "\n",
        "    # Train logistic regression model for suitability prediction\n",
        "    X_suitability = labeled_data[['match_percentage']]\n",
        "    y_suitability = labeled_data['suitable']\n",
        "\n",
        "    suitability_model = LogisticRegression()\n",
        "    suitability_model.fit(X_suitability, y_suitability)\n",
        "\n",
        "    print(\"Model trained successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L41vkRxPYYhY",
        "outputId": "87e98379-e6d7-43cf-ac73-4d776a5e1fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labeled data created successfully.\n",
            "    match_percentage  suitable\n",
            "0         100.000000         1\n",
            "1           8.832553         0\n",
            "2          11.997773         0\n",
            "3          20.150485         0\n",
            "4          10.528153         0\n",
            "5           9.561241         0\n",
            "6          21.994874         0\n",
            "7          21.267344         0\n",
            "8          16.767357         0\n",
            "9          25.742033         0\n",
            "10        100.000000         1\n",
            "11          8.832553         0\n",
            "12         11.997773         0\n",
            "13         20.150485         0\n",
            "14         10.528153         0\n",
            "15          9.561241         0\n",
            "16         21.994874         0\n",
            "17         21.267344         0\n",
            "18         16.767357         0\n",
            "19         25.742033         0\n",
            "20        100.000000         1\n",
            "21          8.832553         0\n",
            "22         11.997773         0\n",
            "23         20.150485         0\n",
            "24         10.528153         0\n",
            "25          9.561241         0\n",
            "26         21.994874         0\n",
            "27         21.267344         0\n",
            "28         16.767357         0\n",
            "29         25.742033         0\n",
            "Model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Predict Suitability"
      ],
      "metadata": {
        "id": "eyBJNJ92i9VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text from PDF\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    reader = PdfReader(file_path)\n",
        "    text = ''\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return preprocess_text(text)\n",
        "\n",
        "# Prompt for job description and resume file\n",
        "def get_user_input():\n",
        "    job_description = input(\"Please enter the job description: \").strip()\n",
        "    if not job_description:\n",
        "        print(\"Job description cannot be empty!\")\n",
        "        return None, None\n",
        "\n",
        "    resume_pdf_path = input(\"Please enter the path to the resume PDF file: \").strip()\n",
        "    return job_description, resume_pdf_path\n",
        "\n",
        "# Example usage\n",
        "job_description, resume_pdf_path = get_user_input()\n",
        "if job_description and resume_pdf_path:\n",
        "    job_description = preprocess_text(job_description)\n",
        "    resume_text = extract_text_from_pdf(resume_pdf_path)\n",
        "    match_percentage = calculate_similarity(job_description, resume_text)\n",
        "    print(f'Match Percentage: {match_percentage}%')\n",
        "\n",
        "    # Predict suitability based on match percentage\n",
        "    suitability_prediction = suitability_model.predict([[match_percentage]])\n",
        "    suitability = 'Yes' if suitability_prediction[0] == 1 else 'No'\n",
        "\n",
        "    print(f'Is the candidate suitable for the job? {suitability}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivkU-w13YYeg",
        "outputId": "09fe1f86-dfb6-4720-db43-a27a81ddc4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the job description: We are looking for passionate engineers and researchers that want to contribute in this exciting and fast moving field of Deep Learning and Research.  Our client is a highly awarded AI and Machine Learning lab, which is disrupting the multi billion dollar Agriculture and commodities business globally. They are recognized as a de-facto business for expert AI capability in solutions that satisfy real world challenges in near real time.  As the Lead Engineer - Deep Learning, you will be responsible for leading research, software implementation for new concept prototypes in the areas of computer vision and deep learning.  What you will do: • Focusing on developing new concepts and user experiences through rapid prototyping and collaboration with the best-in-class research and development team. • Reading research papers and implementing state-of-the-art techniques for computer vision • Building and managing datasets. • Providing Rapid experimentation, analysis, and deployment of machine/deep learning models • Based on requirements set by the team, helping develop new and rapid prototypes • Developing end to end products for problems related to agritech and other use cases • Leading the deep learning team  What you need to have: • MS/ME/PhD in Computer Science, Computer Engineering equivalent Proficient in Python and C++, CUDA a plus • International conference papers/Patents, Algorithm design, deep learning development, programming (Python, C/C++) • Knowledge of multiple deep-learning frameworks, such as Caffe, TensorFlow, Theano, Torch/PyTorch • Problem Solving: Deep learning development • Vision, perception, control, planning algorithm development • Track record of excellence in the machine learning / perception / control, including patents, publications to international conferences or journals. • Communications: Good communication skills\n",
            "Please enter the path to the resume PDF file: /content/TejasH MistrY.pdf\n",
            "Match Percentage: 28.56135024347329%\n",
            "Is the candidate suitable for the job? No\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xyrkGYSxYYJJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}